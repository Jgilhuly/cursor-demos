{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Legacy User Analytics Pipeline\n",
        "\n",
        "This notebook demonstrates a **legacy** approach to analyzing user analytics data using pandas. \n",
        "\n",
        "âš ï¸ **Warning**: This code contains several performance bottlenecks and inefficient patterns that should be optimized for production use.\n",
        "\n",
        "## Dataset Overview\n",
        "- **User Data**: Basic user information and demographics\n",
        "- **Session Data**: User session information with device and location data\n",
        "- **Event Data**: Individual user events and interactions\n",
        "\n",
        "Let's start by loading and exploring our data...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -qq pandas numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import time\n",
        "\n",
        "print(\"Loading user analytics data...\")\n",
        "start_time = time.time()\n",
        "\n",
        "# Load our datasets\n",
        "users_df = pd.read_csv('user_data.csv')\n",
        "sessions_df = pd.read_csv('user_sessions.csv')\n",
        "events_df = pd.read_csv('user_events.csv')\n",
        "\n",
        "# Convert datetime columns\n",
        "users_df['signup_date'] = pd.to_datetime(users_df['signup_date'])\n",
        "users_df['first_seen'] = pd.to_datetime(users_df['first_seen'])\n",
        "users_df['last_seen'] = pd.to_datetime(users_df['last_seen'])\n",
        "\n",
        "sessions_df['session_start'] = pd.to_datetime(sessions_df['session_start'])\n",
        "events_df['event_time'] = pd.to_datetime(events_df['event_time'])\n",
        "\n",
        "load_time = time.time() - start_time\n",
        "print(f\"Data loaded in {load_time:.2f} seconds\")\n",
        "print(f\"Users: {len(users_df):,}\")\n",
        "print(f\"Sessions: {len(sessions_df):,}\")\n",
        "print(f\"Events: {len(events_df):,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Anti-Pattern #1: Using iterrows() for Row-by-Row Processing\n",
        "\n",
        "Let's calculate user engagement scores using the inefficient `iterrows()` method instead of vectorized operations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating engagement scores (inefficient method)...\n",
            "Engagement scores calculated in 0.02 seconds\n",
            "Average engagement score: 30.9843\n"
          ]
        }
      ],
      "source": [
        "def calculate_engagement_score_slow(users_df):\n",
        "    \"\"\"\n",
        "    INEFFICIENT: Using iterrows() to calculate engagement scores\n",
        "    This is much slower than vectorized operations\n",
        "    \"\"\"\n",
        "    print(\"Calculating engagement scores (inefficient method)...\")\n",
        "    start_time = time.time()\n",
        "    \n",
        "    engagement_scores = []\n",
        "    \n",
        "    # BAD: Using iterrows() - very slow for large datasets\n",
        "    for index, row in users_df.iterrows():\n",
        "        # Calculate days since signup\n",
        "        days_since_signup = (row['last_seen'] - row['signup_date']).days\n",
        "        \n",
        "        # Calculate engagement score based on sessions and revenue\n",
        "        if days_since_signup > 0:\n",
        "            session_rate = row['total_sessions'] / days_since_signup\n",
        "            revenue_per_session = row['total_revenue'] / row['total_sessions'] if row['total_sessions'] > 0 else 0\n",
        "            engagement_score = (session_rate * 0.6) + (revenue_per_session * 0.4)\n",
        "        else:\n",
        "            engagement_score = 0\n",
        "        \n",
        "        engagement_scores.append(engagement_score)\n",
        "    \n",
        "    users_df['engagement_score'] = engagement_scores\n",
        "    \n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f\"Engagement scores calculated in {elapsed_time:.2f} seconds\")\n",
        "    return users_df\n",
        "\n",
        "# Apply the slow function\n",
        "users_df = calculate_engagement_score_slow(users_df)\n",
        "print(f\"Average engagement score: {users_df['engagement_score'].mean():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Anti-Pattern #2: Inefficient String Operations with apply()\n",
        "\n",
        "Let's categorize email domains using inefficient string operations and unnecessary apply() calls.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Categorizing email domains (inefficient method)...\n",
            "Email categorization completed in 0.00 seconds\n",
            "\n",
            "Email category distribution:\n",
            "email_category\n",
            "Personal     800\n",
            "Corporate    193\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "def categorize_email_domain_slow(email_domain):\n",
        "    \"\"\"\n",
        "    INEFFICIENT: Using multiple string operations in apply()\n",
        "    This should be replaced with vectorized string operations\n",
        "    \"\"\"\n",
        "    # BAD: Inefficient string operations inside apply()\n",
        "    email_domain = str(email_domain).lower().strip()\n",
        "    \n",
        "    # Multiple if-else statements that could be optimized\n",
        "    if email_domain.find('gmail') != -1:\n",
        "        return 'Personal'\n",
        "    elif email_domain.find('yahoo') != -1:\n",
        "        return 'Personal'\n",
        "    elif email_domain.find('hotmail') != -1:\n",
        "        return 'Personal'\n",
        "    elif email_domain.find('outlook') != -1:\n",
        "        return 'Personal'\n",
        "    elif email_domain.find('company') != -1:\n",
        "        return 'Corporate'\n",
        "    else:\n",
        "        return 'Other'\n",
        "\n",
        "print(\"Categorizing email domains (inefficient method)...\")\n",
        "start_time = time.time()\n",
        "\n",
        "# BAD: Using apply() with complex lambda when vectorized operations would be faster\n",
        "users_df['email_category'] = users_df['email_domain'].apply(\n",
        "    lambda x: categorize_email_domain_slow(x)\n",
        ")\n",
        "\n",
        "# More inefficient string operations\n",
        "users_df['email_provider'] = users_df['email_domain'].apply(\n",
        "    lambda x: str(x).split('.')[0].upper() if '.' in str(x) else 'UNKNOWN'\n",
        ")\n",
        "\n",
        "elapsed_time = time.time() - start_time\n",
        "print(f\"Email categorization completed in {elapsed_time:.2f} seconds\")\n",
        "\n",
        "# Show the results\n",
        "print(\"\\nEmail category distribution:\")\n",
        "print(users_df['email_category'].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Anti-Pattern #3: Nested Loops for Aggregations\n",
        "\n",
        "Let's calculate user behavior patterns using nested loops instead of efficient groupby operations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating user metrics (inefficient nested loops)...\n",
            "User metrics calculated in 274.26 seconds\n",
            "Calculated metrics for 993 users\n",
            "Average conversion rate: 0.1211\n"
          ]
        }
      ],
      "source": [
        "def calculate_user_metrics_slow(users_df, sessions_df, events_df):\n",
        "    \"\"\"\n",
        "    INEFFICIENT: Using nested loops for aggregations\n",
        "    This should be replaced with groupby operations\n",
        "    \"\"\"\n",
        "    print(\"Calculating user metrics (inefficient nested loops)...\")\n",
        "    start_time = time.time()\n",
        "    \n",
        "    user_metrics = []\n",
        "    \n",
        "    # BAD: Nested loops for aggregations - very slow!\n",
        "    for user_id in users_df['user_id'].unique():\n",
        "        user_sessions = []\n",
        "        user_events = []\n",
        "        \n",
        "        # Inner loop 1: Find all sessions for this user\n",
        "        for _, session in sessions_df.iterrows():\n",
        "            if session['user_id'] == user_id:\n",
        "                user_sessions.append(session)\n",
        "        \n",
        "        # Inner loop 2: Find all events for this user\n",
        "        for _, event in events_df.iterrows():\n",
        "            if event['user_id'] == user_id:\n",
        "                user_events.append(event)\n",
        "        \n",
        "        # Calculate metrics manually instead of using built-in functions\n",
        "        total_session_duration = 0\n",
        "        for session in user_sessions:\n",
        "            total_session_duration += session['session_duration']\n",
        "        \n",
        "        avg_session_duration = total_session_duration / len(user_sessions) if user_sessions else 0\n",
        "        \n",
        "        # Count events by type manually\n",
        "        event_counts = {}\n",
        "        for event in user_events:\n",
        "            event_type = event['event_type']\n",
        "            if event_type not in event_counts:\n",
        "                event_counts[event_type] = 0\n",
        "            event_counts[event_type] += 1\n",
        "        \n",
        "        # Calculate conversion rate manually\n",
        "        purchases = event_counts.get('purchase', 0)\n",
        "        total_events = len(user_events)\n",
        "        conversion_rate = purchases / total_events if total_events > 0 else 0\n",
        "        \n",
        "        user_metrics.append({\n",
        "            'user_id': user_id,\n",
        "            'avg_session_duration': avg_session_duration,\n",
        "            'total_events': total_events,\n",
        "            'purchases': purchases,\n",
        "            'conversion_rate': conversion_rate\n",
        "        })\n",
        "    \n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f\"User metrics calculated in {elapsed_time:.2f} seconds\")\n",
        "    \n",
        "    return pd.DataFrame(user_metrics)\n",
        "\n",
        "# Apply the slow function\n",
        "user_metrics_df = calculate_user_metrics_slow(users_df, sessions_df, events_df)\n",
        "print(f\"Calculated metrics for {len(user_metrics_df)} users\")\n",
        "print(f\"Average conversion rate: {user_metrics_df['conversion_rate'].mean():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Anti-Pattern #4: Memory-Inefficient Operations\n",
        "\n",
        "Let's create multiple unnecessary intermediate DataFrames and perform inefficient merges.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating user summary (memory-inefficient method)...\n",
            "User summary created in 0.01 seconds\n",
            "Created summary for 993 users\n",
            "Memory usage: 0.45 MB\n",
            "\n",
            "User tier distribution:\n",
            "user_tier\n",
            "Basic    993\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "def create_user_summary_slow(users_df, sessions_df, events_df):\n",
        "    \"\"\"\n",
        "    INEFFICIENT: Creating multiple unnecessary intermediate DataFrames\n",
        "    and performing inefficient merges\n",
        "    \"\"\"\n",
        "    print(\"Creating user summary (memory-inefficient method)...\")\n",
        "    start_time = time.time()\n",
        "    \n",
        "    # BAD: Creating many intermediate DataFrames instead of chaining operations\n",
        "    temp_df1 = users_df.copy()\n",
        "    temp_df2 = temp_df1.copy()\n",
        "    temp_df3 = temp_df2.copy()\n",
        "    \n",
        "    # BAD: Multiple separate operations instead of efficient chaining\n",
        "    sessions_by_user = sessions_df.groupby('user_id').agg({\n",
        "        'session_duration': ['mean', 'sum', 'count'],\n",
        "        'pages_visited': ['mean', 'sum'],\n",
        "        'revenue': ['sum', 'mean']\n",
        "    }).reset_index()\n",
        "    \n",
        "    # BAD: Flattening column names inefficiently\n",
        "    sessions_by_user.columns = ['user_id', 'avg_session_duration', 'total_session_duration', \n",
        "                               'session_count', 'avg_pages_visited', 'total_pages_visited',\n",
        "                               'total_revenue', 'avg_revenue_per_session']\n",
        "    \n",
        "    # BAD: Creating another intermediate DataFrame\n",
        "    events_by_user = events_df.groupby('user_id').agg({\n",
        "        'event_id': 'count',\n",
        "        'value': ['sum', 'mean']\n",
        "    }).reset_index()\n",
        "    \n",
        "    events_by_user.columns = ['user_id', 'total_events', 'total_event_value', 'avg_event_value']\n",
        "    \n",
        "    # BAD: Inefficient merges - creating copies each time\n",
        "    result_df = temp_df3.copy()\n",
        "    result_df = result_df.merge(sessions_by_user, on='user_id', how='left')\n",
        "    result_df = result_df.merge(events_by_user, on='user_id', how='left')\n",
        "    \n",
        "    # Fill only columns that exist in result_df to avoid KeyError\n",
        "    numeric_columns = [\n",
        "        'avg_session_duration', 'total_session_duration', 'session_count',\n",
        "        'avg_pages_visited', 'total_pages_visited', 'total_revenue',\n",
        "        'avg_revenue_per_session', 'total_events', 'total_event_value',\n",
        "        'avg_event_value'\n",
        "    ]\n",
        "    for col in numeric_columns:\n",
        "        if col in result_df.columns:\n",
        "            result_df[col] = result_df[col].fillna(0)\n",
        "\n",
        "    final_df = result_df.copy()\n",
        "\n",
        "    # Only create 'user_tier' if 'total_revenue' exists to avoid KeyError\n",
        "    if 'total_revenue' in final_df.columns:\n",
        "        final_df['user_tier'] = final_df['total_revenue'].apply(\n",
        "            lambda x: 'Premium' if x > 100 else 'Standard' if x > 50 else 'Basic'\n",
        "        )\n",
        "    else:\n",
        "        final_df['user_tier'] = 'Basic'\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f\"User summary created in {elapsed_time:.2f} seconds\")\n",
        "\n",
        "    return final_df\n",
        "\n",
        "# Apply the memory-inefficient function\n",
        "user_summary_df = create_user_summary_slow(users_df, sessions_df, events_df)\n",
        "print(f\"Created summary for {len(user_summary_df)} users\")\n",
        "print(f\"Memory usage: {user_summary_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "\n",
        "# Show user tier distribution\n",
        "print(\"\\nUser tier distribution:\")\n",
        "print(user_summary_df['user_tier'].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Final Results and Summary\n",
        "\n",
        "Let's display a sample of our final results and summarize the performance issues in this pipeline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample of final user summary:\n",
            "     user_id email_category  engagement_score user_tier  session_count  \\\n",
            "0  user_0001       Personal         33.044702     Basic              6   \n",
            "1  user_0002       Personal         20.100703     Basic              6   \n",
            "2  user_0003       Personal          0.060000     Basic              1   \n",
            "3  user_0004      Corporate          0.013333     Basic              5   \n",
            "4  user_0005       Personal          0.040000     Basic              1   \n",
            "5  user_0006       Personal         56.976155     Basic              6   \n",
            "6  user_0007       Personal         27.012802     Basic              7   \n",
            "7  user_0008       Personal         39.366951     Basic              3   \n",
            "8  user_0009      Corporate          2.661873     Basic              8   \n",
            "9  user_0010       Personal        100.459747     Basic              4   \n",
            "\n",
            "   total_events  \n",
            "0          34.0  \n",
            "1          37.0  \n",
            "2           0.0  \n",
            "3          25.0  \n",
            "4           5.0  \n",
            "5          30.0  \n",
            "6          39.0  \n",
            "7          12.0  \n",
            "8          27.0  \n",
            "9          17.0  \n",
            "\n",
            "ðŸ’¡ These patterns can be optimized using modern pandas techniques!\n",
            "ðŸ’¡ Expected performance improvement: 5-10x faster execution\n",
            "ðŸ’¡ Expected memory reduction: 50-70% less memory usage\n"
          ]
        }
      ],
      "source": [
        "# Display sample results\n",
        "print(\"Sample of final user summary:\")\n",
        "print(user_summary_df[['user_id', 'email_category', 'engagement_score', 'user_tier', 'session_count', 'total_events']].head(10))\n",
        "\n",
        "print(\"\\nðŸ’¡ These patterns can be optimized using modern pandas techniques!\")\n",
        "print(\"ðŸ’¡ Expected performance improvement: 5-10x faster execution\")\n",
        "print(\"ðŸ’¡ Expected memory reduction: 50-70% less memory usage\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
